{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3359fe01",
   "metadata": {},
   "source": [
    "# MVP of setting up a mulit-agent LLM chain\n",
    "\n",
    "Specifically for the financial sector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3503e319",
   "metadata": {},
   "source": [
    "# Install & Import Depediencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d219f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c01ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find platform independent libraries <prefix>\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find platform independent libraries <prefix>\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find platform independent libraries <prefix>\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find platform independent libraries <prefix>\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ackaging (c:\\Users\\aidan\\Documents\\coding\\.venv\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# Ensure necessary imports are available\n",
    "#%%capture --no-stderr\n",
    "%pip install --quiet -U langchain \n",
    "%pip install --quiet -U langgraph \n",
    "%pip install --quiet -U openai \n",
    "%pip install --quiet -U python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9643f91",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StateGraph, END\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcheckpoint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "import dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint import MemorySaver\n",
    "\n",
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f9d0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "class StockMarketAgentState:\n",
    "    \"\"\"Defines the state for the multi-agent workflow.\"\"\"\n",
    "    def __init__(self, question: str):\n",
    "        self.question = question\n",
    "        self.expert_analyses: List[Dict[str, str]] = []\n",
    "        self.consensus_summary: str = \"\"\n",
    "\n",
    "class StockMarketAgentJupyter:\n",
    "    def __init__(self, model_name=\"gpt-4-turbo\"):\n",
    "        \"\"\"Initialize the agent with a specified language model.\"\"\"\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name, \n",
    "            temperature=0.3, \n",
    "            max_tokens=1000\n",
    "        )\n",
    "    \n",
    "    async def run_expert_analysis(self, expert_func, state):\n",
    "        \"\"\"Async wrapper for expert analysis to handle potential delays.\"\"\"\n",
    "        try:\n",
    "            result = expert_func(state)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"expert\": \"Error\",\n",
    "                \"analysis\": f\"Analysis failed: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    def financial_analyst(self, state):\n",
    "        \"\"\"Expert focused on fundamental financial analysis.\"\"\"\n",
    "        prompt = f\"\"\"Analyze the stock market question from a financial fundamentals perspective:\n",
    "        Question: {state.question}\n",
    "        \n",
    "        Provide analysis focusing on:\n",
    "        - Valuation metrics\n",
    "        - Company/market fundamentals\n",
    "        - Long-term financial health\n",
    "        \n",
    "        Your analysis should be concise, precise, and data-driven.\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return {\n",
    "            \"expert\": \"Financial Analyst\",\n",
    "            \"analysis\": response\n",
    "        }\n",
    "    \n",
    "    def news_analyst(self, state):\n",
    "        \"\"\"Expert analyzing recent news and sentiment.\"\"\"\n",
    "        prompt = f\"\"\"Analyze recent news and sentiment related to the market question:\n",
    "        Question: {state.question}\n",
    "        \n",
    "        Provide analysis focusing on:\n",
    "        - Recent significant news\n",
    "        - Media sentiment\n",
    "        - Potential market-moving events\n",
    "        \n",
    "        Your analysis should be timely and contextual.\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return {\n",
    "            \"expert\": \"News Analyst\", \n",
    "            \"analysis\": response\n",
    "        }\n",
    "    \n",
    "    def day_trader(self, state):\n",
    "        \"\"\"Expert focused on technical analysis and short-term trends.\"\"\"\n",
    "        prompt = f\"\"\"Perform technical analysis for the market question:\n",
    "        Question: {state.question}\n",
    "        \n",
    "        Provide analysis focusing on:\n",
    "        - Short-term price patterns\n",
    "        - Technical indicators\n",
    "        - Trading volume\n",
    "        - Potential entry/exit signals\n",
    "        \n",
    "        Your analysis should be sharp and actionable.\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return {\n",
    "            \"expert\": \"Day Trader\",\n",
    "            \"analysis\": response\n",
    "        }\n",
    "    \n",
    "    def macro_economist(self, state):\n",
    "        \"\"\"Expert analyzing broader economic indicators.\"\"\"\n",
    "        prompt = f\"\"\"Examine the market question through a macroeconomic lens:\n",
    "        Question: {state.question}\n",
    "        \n",
    "        Provide analysis focusing on:\n",
    "        - Broader economic indicators\n",
    "        - Global economic trends\n",
    "        - Monetary and fiscal policy impacts\n",
    "        \n",
    "        Your analysis should provide a big-picture perspective.\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return {\n",
    "            \"expert\": \"Macro Economic Expert\",\n",
    "            \"analysis\": response\n",
    "        }\n",
    "    \n",
    "    def psychology_expert(self, state):\n",
    "        \"\"\"Expert evaluating market sentiment and behavioral aspects.\"\"\"\n",
    "        prompt = f\"\"\"Analyze market psychology related to the question:\n",
    "        Question: {state.question}\n",
    "        \n",
    "        Provide analysis focusing on:\n",
    "        - Market sentiment\n",
    "        - Investor psychology\n",
    "        - Potential behavioral biases\n",
    "        - Emotional market drivers\n",
    "        \n",
    "        Your analysis should reveal underlying psychological factors.\"\"\"\n",
    "        \n",
    "        response = self.llm.invoke(prompt).content\n",
    "        return {\n",
    "            \"expert\": \"Economic Psychology Expert\",\n",
    "            \"analysis\": response\n",
    "        }\n",
    "    \n",
    "    async def run_analysis(self, question: str):\n",
    "        \"\"\"Async method to run the stock market analysis.\"\"\"\n",
    "        # Create initial state\n",
    "        state = StockMarketAgentState(question)\n",
    "        \n",
    "        # Define expert functions in order\n",
    "        expert_funcs = [\n",
    "            self.financial_analyst,\n",
    "            self.news_analyst,\n",
    "            self.day_trader,\n",
    "            self.macro_economist,\n",
    "            self.psychology_expert\n",
    "        ]\n",
    "        \n",
    "        # Run analyses sequentially\n",
    "        for expert_func in expert_funcs:\n",
    "            analysis = await self.run_expert_analysis(expert_func, state)\n",
    "            state.expert_analyses.append(analysis)\n",
    "        \n",
    "        # Generate consensus\n",
    "        consensus_prompt = f\"\"\"Based on the following expert analyses, generate a concise, one-sentence consensus summary:\n",
    "        \n",
    "        {chr(10).join([f\"{analysis['expert']}: {analysis['analysis']}\" for analysis in state.expert_analyses])}\n",
    "        \n",
    "        Synthesize these perspectives into a clear, actionable insight.\"\"\"\n",
    "        \n",
    "        state.consensus_summary = self.llm.invoke(consensus_prompt).content\n",
    "        \n",
    "        # Prepare report\n",
    "        report = {\n",
    "            \"question\": state.question,\n",
    "            \"consensus_summary\": state.consensus_summary,\n",
    "            \"expert_insights\": state.expert_analyses,\n",
    "            \"follow_up_prompt\": \"Would you like me to elaborate on any part of this analysis?\"\n",
    "        }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def display_report(self, report):\n",
    "        \"\"\"Format and display the analysis report.\"\"\"\n",
    "        print(\"=== Stock Market Analysis Report ===\")\n",
    "        print(f\"Question: {report['question']}\\n\")\n",
    "        print(\"Consensus Summary:\")\n",
    "        print(report['consensus_summary'], \"\\n\")\n",
    "        \n",
    "        print(\"Expert Insights:\")\n",
    "        for insight in report['expert_insights']:\n",
    "            print(f\"- {insight['expert']}:\")\n",
    "            print(f\"  {insight['analysis']}\\n\")\n",
    "        \n",
    "        print(\"Follow-up:\", report['follow_up_prompt'])\n",
    "\n",
    "# Example usage in Jupyter Notebook\n",
    "async def main():\n",
    "    # Ensure you have set OPENAI_API_KEY in your .env file\n",
    "    agent = StockMarketAgentJupyter()\n",
    "    \n",
    "    # Example market question\n",
    "    market_question = \"Do you expect the S&P 500 to go up or down this week?\"\n",
    "    \n",
    "    # Run the analysis\n",
    "    report = await agent.run_analysis(market_question)\n",
    "    \n",
    "    # Display the report\n",
    "    agent.display_report(report)\n",
    "\n",
    "# To run in Jupyter, use:\n",
    "# await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c42fc34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b66f001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df2e554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
